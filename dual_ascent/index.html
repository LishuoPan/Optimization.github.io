<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Daul Ascent - Optimization</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Daul Ascent";
    var mkdocs_page_input_path = "dual_ascent.md";
    var mkdocs_page_url = "/dual_ascent/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Optimization</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Introduciton</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Daul Ascent</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#21-dual-ascent">2.1 Dual Ascent</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#when-g-is-not-differentiable">When g is not differentiable</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#22-dual-decomposition">2.2 Dual Decomposition</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#implementation">Implementation</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#summary">Summary</a></li>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../Augmented Lagrangians and the Method of Multipliers/">Augmented Lagrangian and the Method of Multipliers</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../ADMM/">ADMM</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Optimization</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Daul Ascent</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h4 id="21-dual-ascent">2.1 Dual Ascent</h4>
<p>Problem to solve:
<script type="math/tex; mode=display">
\begin{equation}
\mbox{minimize} \ \ f(x) \\
\mbox{subject  to} \ \ Ax=b  \tag{2.1}
\\x\ \in\ \mathbb{R}^{n} \ where \ A\  \in\  \mathbb{R}^{m\times n}\ and\ f:\mathbb{R}^{n} \rightarrow \mathbb{R}\ is\ convex
\end{equation}
</script>
</p>
<p>The Lagrangian for (2.1) is:
<script type="math/tex; mode=display">
L(x,y)=f(x)+y^{T}(Ax-b) 
</script>
The dual function is:
<script type="math/tex; mode=display">
g(y) =\inf\limits_{x} L(x,y)=-f^{\ast}(-A^{T}y)-b^{T}y
</script>
where <script type="math/tex">y</script> is the dual variable or Lagrange multiplier, and the <script type="math/tex">f^*</script> is the conjugate of the <script type="math/tex">f</script>. This function says taht <script type="math/tex">g(y)</script> is convex of <script type="math/tex">y</script>.</p>
<p>The definition of <script type="math/tex">f^{*}(y) </script>:
<script type="math/tex; mode=display">
f^{*}(y):\sup\limits_{x\in domf}:(y^{T}x-f(x))
</script>
<script type="math/tex">\color{blue}{Proof}</script>:
<script type="math/tex; mode=display">
\begin{align}
g(y) &= \inf\limits_{x} L(x,y)=\inf\limits_{x}f(x) +y^{T}Ax-y^{T}b\\&=-\sup\limits_{x}-f(x)+y^{T}(-Ax)+y^{T}b\\&=-f^{*}(-A^{T}y)-y^{T}b
\end{align}
</script>
Now, the dual problem is 
<script type="math/tex; mode=display">
\mbox{maximize} \ g(y)
</script>
with variable <script type="math/tex">y\in \mathbb{R}^{m}</script>.</p>
<p>Assuming the strong duality holds. the optimal values of the primal and dual problems are the same.</p>
<p>The primal optimal point <script type="math/tex">x^{*}</script> form a dual optimal point <script type="math/tex">y^{*}</script> as 
<script type="math/tex; mode=display">
x^{*}=arg\min\limits_{x} L(x,y^{*}),
</script>
provided that there is only one minimizer of <script type="math/tex">L(x,y^{*})</script>. </p>
<p>The notation <script type="math/tex">\mbox{argmin}_{x}F(x)</script> denotes any minimizer of <script type="math/tex">F</script>. </p>
<p>In the <script type="math/tex">dual\ ascent\ method</script>, we use <strong>greadient ascent</strong> to solve dual problem. Assuming <script type="math/tex">g</script> is differentiable. We first find <script type="math/tex">x^{+}=argmin_{x}L(x,y)</script>, then the gradient <script type="math/tex">\nabla g(y)=Ax^{+}-b</script>, which is the residual for the equality constraint. 
<script type="math/tex; mode=display">
\begin{align}
x^{k+1}&:=arg\min\limits_{x}L(x,y^{k})\tag{2.2}\\
y^{k+1}&:=y^{k}+\alpha^{k}(Ax^{k+1}-b),\tag{2.3}
\end{align}
</script>
where <script type="math/tex">\alpha^{k}>0</script> is a step size, the <script type="math/tex">k</script> is the iteration counter. With appropriate choice of <script type="math/tex">\alpha^{k}</script>, <script type="math/tex">g(y^{k+1})>g(y^{k})</script>. </p>
<p>The principle is <script type="math/tex">\max\limits_{y}g(y)=\max\limits_{x}L(x,y) </script>, optimizing x and y alternatively to reach <script type="math/tex">L(x^{*},y^{*})</script>. </p>
<h6 id="when-g-is-not-differentiable">When <script type="math/tex">g</script> is not differentiable</h6>
<p>The residual <script type="math/tex">Ax^{k+1}-b</script> is not the gradient of <script type="math/tex">g</script>, but the negative of a subgradient of <script type="math/tex">-g</script>.  It is often that <script type="math/tex">g(y^{k+1})\ngtr g(y^{k})</script>. The algorithm is usually called the <script type="math/tex">dual\ subgradient\ method</script>. </p>
<p>If <script type="math/tex">\alpha^{k}</script> is chosen appropriately and several other assumptions hold, then <script type="math/tex">x^{k}</script> converges to an optimal point and <script type="math/tex">y^{k}</script> converges to an opotimal dual point. </p>
<p>However, these assumptions <em>do not hold</em> in many cases. For example,  if <script type="math/tex">f</script> is a nonzero affine function of any component of x, <script type="math/tex">L</script> is unbounded below in <script type="math/tex">x</script> for most <script type="math/tex">y</script>. </p>
<h4 id="22-dual-decomposition">2.2 Dual Decomposition</h4>
<p>The <script type="math/tex">\color{blue}{\mbox{major benefit}}</script> of the dual ascent is that it can lead to a decentralized algorithm in some cases.</p>
<p>Suppose, <script type="math/tex">f</script> is <em>separable</em>, meaning that
<script type="math/tex; mode=display">
f(x)=\sum_{i=1}^{N}f_{i}(x_i),
</script>
where <script type="math/tex">x=(x_1,â€¦,x_N)</script> and the variables <script type="math/tex">x_i\in\mathbb{R}^{n_i}</script> are subvectors of <script type="math/tex">x</script>. </p>
<p>Partitioning the matrix <script type="math/tex">A</script> conformably as 
<script type="math/tex; mode=display">
A=[A_1\cdot\cdot\cdot A_N],
</script>
so <script type="math/tex">Ax=\sum_{i=1}^{N}A_ix_i</script>, the Lagrangian is 
<script type="math/tex; mode=display">
L(x,y )=\sum_{i=1}^{N}L_{i}(x_i,y)=\sum_{i=1}^{N}(f_{i}+y^TA_ix_i-(1/N)y^Tb)\\\mbox{such that } L(x,y)=f(x)+y^{T}(Ax-b)
</script>
which is also separable in <script type="math/tex">x</script>. <script type="math/tex">\color{blue}{\mbox{The x-minimization step splits into N separate prolems that can be solved in parallel.}}</script>
</p>
<p>Now, the algorithm is 
<script type="math/tex; mode=display">
\begin{align}
x^{k+1}_i&:=arg\min\limits_{x_i}L_i(x_i,y^k)\tag{2.4}\\
y^{k+1}&:=y^k+\alpha^{k}(Ax^{k+1}-b).\tag{2.5}
\end{align}
</script>
In this case, we refer to the dual ascent mehtod as <em>dual decomposition</em>. Dual decomposition is used to do dual acent method for separable <script type="math/tex">f(x)</script>. Dual decomposition is distributed dual ascent method. </p>
<h6 id="implementation">Implementation</h6>
<p>Each iteration of the dual decomposition methods inclued <em>broadcast</em> and <em>gather</em> operation.  First, <script type="math/tex">A_ix_i^{k+1}</script> are collected(gathered). Second, compute the residual <script type="math/tex">Ax^{k+1}-b</script>.  Then, compute the (global) dual variable <script type="math/tex">y^{k+1}</script>. Finally, distributed (broadcast)  to the processors that carry out the <script type="math/tex">N</script> individual <script type="math/tex">x_i</script> minimization steps (2.4). </p>
<h4 id="summary">Summary</h4>
<p>Advantages: </p>
<p>Disadvantages:</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Augmented Lagrangians and the Method of Multipliers/" class="btn btn-neutral float-right" title="Augmented Lagrangian and the Method of Multipliers">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href=".." class="btn btn-neutral" title="Introduciton"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href=".." style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../Augmented Lagrangians and the Method of Multipliers/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      <script src="../search/require.js"></script>
      <script src="../search/search.js"></script>

</body>
</html>
