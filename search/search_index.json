{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Optimization\n\n\nFor full documentation visit \nmkdocs.org\n.\n\n\nDual Ascent\n\n\n\n\nDual Ascent\n - \n\n\nDual Decomposition\n -\n\n\n\n\nAugmented Lagrangians and the Method of Multipliers\n\n\nmkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-optimization", 
            "text": "For full documentation visit  mkdocs.org .", 
            "title": "Welcome to Optimization"
        }, 
        {
            "location": "/#dual-ascent", 
            "text": "Dual Ascent  -   Dual Decomposition  -", 
            "title": "Dual Ascent"
        }, 
        {
            "location": "/#augmented-lagrangians-and-the-method-of-multipliers", 
            "text": "mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.", 
            "title": "Augmented Lagrangians and the Method of Multipliers"
        }, 
        {
            "location": "/dual_ascent/", 
            "text": "Dual Ascent\n\n\nProblem to solve:\n\n\n\\begin{equation}\n\\mbox{minimize} \\ \\ f(x) \\\\\n\\mbox{subject  to} \\ \\ Ax=b  \\tag{2.1}\n\\\\x\\ \\in\\ \\mathbb{R}^{n} \\ where \\ A\\  \\in\\  \\mathbb{R}^{m\\times n}\\ and\\ f:\\mathbb{R}^{n} \\rightarrow \\mathbb{R}\\ is\\ convex\n\\end{equation}\n\n\n\n\n\nThe Lagrangian for (2.1) is:\n\n\nL(x,y)=f(x)+y^{T}(Ax-b) \n\n\nThe dual function is:\n\n\ng(y) =\\inf\\limits_{x} L(x,y)=-f^{\\ast}(-A^{T}y)-b^{T}y\n\n\nwhere \ny\n is the dual variable or Lagrange multiplier, and the \nf^*\n is the conjugate of the \nf\n. This function says taht \ng(y)\n is convex of \ny\n.\n\n\nThe definition of \nf^{*}(y) \n:\n\n\nf^{*}(y):\\sup\\limits_{x\\in domf}:(y^{T}x-f(x))\n\n\n\n\\color{blue}{Proof}\n:\n\n\n\\begin{align}\ng(y) &= \\inf\\limits_{x} L(x,y)=\\inf\\limits_{x}f(x) +y^{T}Ax-y^{T}b\\\\&=-\\sup\\limits_{x}-f(x)+y^{T}(-Ax)+y^{T}b\\\\&=-f^{*}(-A^{T}y)-y^{T}b\n\\end{align}\n\n\nNow, the dual problem is \n\n\n\\mbox{maximize} \\ g(y)\n\n\nwith variable \ny\\in \\mathbb{R}^{m}\n.\n\n\nAssuming the strong duality holds. the optimal values of the primal and dual problems are the same.\n\n\nThe primal optimal point \nx^{*}\n form a dual optimal point \ny^{*}\n as \n\n\nx^{*}=arg\\min\\limits_{x} L(x,y^{*}),\n\n\nprovided that there is only one minimizer of \nL(x,y^{*})\n. \n\n\nThe notation \n\\mbox{argmin}_{x}F(x)\u200b\n denotes any minimizer of \nF\u200b\n. \n\n\nIn the \ndual\\ ascent\\ method\n, we use \ngreadient ascent\n to solve dual problem. Assuming \ng\n is differentiable. We first find \nx^{+}=argmin_{x}L(x,y)\n, then the gradient \n\\nabla g(y)=Ax^{+}-b\n, which is the residual for the equality constraint. \n\n\n\\begin{align}\nx^{k+1}&:=arg\\min\\limits_{x}L(x,y^{k})\\tag{2.2}\\\\\ny^{k+1}&:=y^{k}+\\alpha^{k}(Ax^{k+1}-b),\\tag{2.3}\n\\end{align}\n\n\nwhere \n\\alpha^{k}>0\n is a step size, the \nk\n is the iteration counter. With appropriate choice of \n\\alpha^{k}\n, \ng(y^{k+1})>g(y^{k})\n. \n\n\nThe principle is \n\\max\\limits_{y}g(y)=\\max\\limits_{x}L(x,y) \n, optimizing x and y alternatively to reach \nL(x^{*},y^{*})\n. \n\n\nWhen \ng\n is not differentiable\n\n\nThe residual \nAx^{k+1}-b\n is not the gradient of \ng\n, but the negative of a subgradient of \n-g\n.  It is often that \ng(y^{k+1})\\ngtr g(y^{k})\n. The algorithm is usually called the \ndual\\ subgradient\\ method\n. \n\n\nIf \n\\alpha^{k}\n is chosen appropriately and several other assumptions hold, then \nx^{k}\n converges to an optimal point and \ny^{k}\n converges to an opotimal dual point. \n\n\nHowever, these assumptions \ndo not hold\n in many cases. For example,  if \nf\n is a nonzero affine function of any component of x, \nL\n is unbounded below in \nx\n for most \ny\n. \n\n\nDual Decomposition\n\n\nThe \n\\color{blue}{\\mbox{major benefit}}\n of the dual ascent is that it can lead to a decentralized algorithm in some cases.\n\n\nSuppose, \nf\n is \nseparable\n, meaning that\n\n\nf(x)=\\sum_{i=1}^{N}f_{i}(x_i),\n\n\nwhere \nx=(x_1,\u2026,x_N)\n and the variables \nx_i\\in\\mathbb{R}^{n_i}\n are subvectors of \nx\n. \n\n\nPartitioning the matrix \nA\n conformably as \n\n\nA=[A_1\\cdot\\cdot\\cdot A_N],\n\n\nso \nAx=\\sum_{i=1}^{N}A_ix_i\n, the Lagrangian is \n\n\nL(x,y )=\\sum_{i=1}^{N}L_{i}(x_i,y)=\\sum_{i=1}^{N}(f_{i}+y^TA_ix_i-(1/N)y^Tb)\\\\\\mbox{such that } L(x,y)=f(x)+y^{T}(Ax-b)\n\n\nwhich is also separable in \nx\n. \n\\color{blue}{\\mbox{The x-minimization step splits into N separate prolems that can be solved in parallel.}}\n\n\n\n\nNow, the algorithm is \n\n\n\\begin{align}\nx^{k+1}_i&:=arg\\min\\limits_{x_i}L_i(x_i,y^k)\\tag{2.4}\\\\\ny^{k+1}&:=y^k+\\alpha^{k}(Ax^{k+1}-b).\\tag{2.5}\n\\end{align}\n\n\nIn this case, we refer to the dual ascent mehtod as \ndual decomposition\n. Dual decomposition is used to do dual acent method for separable \nf(x)\n. Dual decomposition is distributed dual ascent method. \n\n\nImplementation:\n\n\nEach iteration of the dual decomposition methods inclued \nbroadcast\n and \ngather\n operation.  First, \nA_ix_i^{k+1}\n are collected(gathered). Second, compute the residual \nAx^{k+1}-b\n.  Then, compute the (global) dual variable \ny^{k+1}\n. Finally, distributed (broadcast)  to the processors that carry out the \nN\n individual \nx_i\n minimization steps (2.4). \n\n\nSummary\n\n\nAdvantages: \n\n\nDisadvantages:", 
            "title": "Daul Ascent"
        }, 
        {
            "location": "/dual_ascent/#dual-ascent", 
            "text": "Problem to solve: \n\\begin{equation}\n\\mbox{minimize} \\ \\ f(x) \\\\\n\\mbox{subject  to} \\ \\ Ax=b  \\tag{2.1}\n\\\\x\\ \\in\\ \\mathbb{R}^{n} \\ where \\ A\\  \\in\\  \\mathbb{R}^{m\\times n}\\ and\\ f:\\mathbb{R}^{n} \\rightarrow \\mathbb{R}\\ is\\ convex\n\\end{equation}   The Lagrangian for (2.1) is: \nL(x,y)=f(x)+y^{T}(Ax-b)  \nThe dual function is: \ng(y) =\\inf\\limits_{x} L(x,y)=-f^{\\ast}(-A^{T}y)-b^{T}y \nwhere  y  is the dual variable or Lagrange multiplier, and the  f^*  is the conjugate of the  f . This function says taht  g(y)  is convex of  y .  The definition of  f^{*}(y)  : \nf^{*}(y):\\sup\\limits_{x\\in domf}:(y^{T}x-f(x))  \\color{blue}{Proof} : \n\\begin{align}\ng(y) &= \\inf\\limits_{x} L(x,y)=\\inf\\limits_{x}f(x) +y^{T}Ax-y^{T}b\\\\&=-\\sup\\limits_{x}-f(x)+y^{T}(-Ax)+y^{T}b\\\\&=-f^{*}(-A^{T}y)-y^{T}b\n\\end{align} \nNow, the dual problem is  \n\\mbox{maximize} \\ g(y) \nwith variable  y\\in \\mathbb{R}^{m} .  Assuming the strong duality holds. the optimal values of the primal and dual problems are the same.  The primal optimal point  x^{*}  form a dual optimal point  y^{*}  as  \nx^{*}=arg\\min\\limits_{x} L(x,y^{*}), \nprovided that there is only one minimizer of  L(x,y^{*}) .   The notation  \\mbox{argmin}_{x}F(x)\u200b  denotes any minimizer of  F\u200b .   In the  dual\\ ascent\\ method , we use  greadient ascent  to solve dual problem. Assuming  g  is differentiable. We first find  x^{+}=argmin_{x}L(x,y) , then the gradient  \\nabla g(y)=Ax^{+}-b , which is the residual for the equality constraint.  \n\\begin{align}\nx^{k+1}&:=arg\\min\\limits_{x}L(x,y^{k})\\tag{2.2}\\\\\ny^{k+1}&:=y^{k}+\\alpha^{k}(Ax^{k+1}-b),\\tag{2.3}\n\\end{align} \nwhere  \\alpha^{k}>0  is a step size, the  k  is the iteration counter. With appropriate choice of  \\alpha^{k} ,  g(y^{k+1})>g(y^{k}) .   The principle is  \\max\\limits_{y}g(y)=\\max\\limits_{x}L(x,y)  , optimizing x and y alternatively to reach  L(x^{*},y^{*}) .", 
            "title": "Dual Ascent"
        }, 
        {
            "location": "/dual_ascent/#when-g-is-not-differentiable", 
            "text": "The residual  Ax^{k+1}-b  is not the gradient of  g , but the negative of a subgradient of  -g .  It is often that  g(y^{k+1})\\ngtr g(y^{k}) . The algorithm is usually called the  dual\\ subgradient\\ method .   If  \\alpha^{k}  is chosen appropriately and several other assumptions hold, then  x^{k}  converges to an optimal point and  y^{k}  converges to an opotimal dual point.   However, these assumptions  do not hold  in many cases. For example,  if  f  is a nonzero affine function of any component of x,  L  is unbounded below in  x  for most  y .", 
            "title": "When g is not differentiable"
        }, 
        {
            "location": "/dual_ascent/#dual-decomposition", 
            "text": "The  \\color{blue}{\\mbox{major benefit}}  of the dual ascent is that it can lead to a decentralized algorithm in some cases.  Suppose,  f  is  separable , meaning that \nf(x)=\\sum_{i=1}^{N}f_{i}(x_i), \nwhere  x=(x_1,\u2026,x_N)  and the variables  x_i\\in\\mathbb{R}^{n_i}  are subvectors of  x .   Partitioning the matrix  A  conformably as  \nA=[A_1\\cdot\\cdot\\cdot A_N], \nso  Ax=\\sum_{i=1}^{N}A_ix_i , the Lagrangian is  \nL(x,y )=\\sum_{i=1}^{N}L_{i}(x_i,y)=\\sum_{i=1}^{N}(f_{i}+y^TA_ix_i-(1/N)y^Tb)\\\\\\mbox{such that } L(x,y)=f(x)+y^{T}(Ax-b) \nwhich is also separable in  x .  \\color{blue}{\\mbox{The x-minimization step splits into N separate prolems that can be solved in parallel.}}   Now, the algorithm is  \n\\begin{align}\nx^{k+1}_i&:=arg\\min\\limits_{x_i}L_i(x_i,y^k)\\tag{2.4}\\\\\ny^{k+1}&:=y^k+\\alpha^{k}(Ax^{k+1}-b).\\tag{2.5}\n\\end{align} \nIn this case, we refer to the dual ascent mehtod as  dual decomposition . Dual decomposition is used to do dual acent method for separable  f(x) . Dual decomposition is distributed dual ascent method.", 
            "title": "Dual Decomposition"
        }, 
        {
            "location": "/dual_ascent/#implementation", 
            "text": "Each iteration of the dual decomposition methods inclued  broadcast  and  gather  operation.  First,  A_ix_i^{k+1}  are collected(gathered). Second, compute the residual  Ax^{k+1}-b .  Then, compute the (global) dual variable  y^{k+1} . Finally, distributed (broadcast)  to the processors that carry out the  N  individual  x_i  minimization steps (2.4).", 
            "title": "Implementation:"
        }, 
        {
            "location": "/dual_ascent/#summary", 
            "text": "Advantages:   Disadvantages:", 
            "title": "Summary"
        }, 
        {
            "location": "/Augmented Lagrangians and the Method of Multipliers/", 
            "text": "Augmented Lagrangians and the Method of Multipliers\n\n\nPurpose: bring \nrobustness\n to the dual ascent method, and in particular, to yield convergence without assumptions like strict convexity or finiteness of \nf\n. \n\n\nThe \naugmented Lagrangians\n is:\n\n\nL_{\\rho}(x,y)=f(x)+y^T(Ax-b)+(\\rho/2)\\|Ax-b\\|^2_2,\\tag{2.6}\n\n\nwhere \n\\rho>0\n is called the \npenalty parameter\n. We can view this problem as adding a norm2 penalty term to Lagrangian. It can also be viewed as the (unaugmented) Lagrangian asscociated with the problem\n\n\n\\mbox{minimize} \\ \\ \\ f(x)+(\\rho/2)\\|Ax=b\\|^2_2\\\\  \\mbox{subject to  } \\ Ax=b \\ \\  \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n\n\nThis part is highly related to proximal algorithm. The associated dual function is \ng_p(y)=\\inf_{x} L_{\\rho}(x,y)\n. \n\n\nThe benefit of including the penalty term (\n(\\rho/2)\\|Ax=b\\|^2_2\u200b\n) is that \ng_\\rho\u200b\n   can be shown to be differentiable under rather mild conditions on the original problem. \n\n\nApplying the dual ascent to the modified problem:\n\n\n\\begin{align}\nx^{k+1}&:=arg\\min\\limits_{x}L_\\rho(x,y^{k})\\tag{2.7}\\\\\ny^{k+1}&:=y^{k}+\\rho(Ax^{k+1}-b),\\tag{2.8}\n\\end{align}\n\n\nwhich is known as the \nmethod of multipiers\n for solving (2.1). The \nx\n-minimization step uses the augmented Lagrangian, and the penalty parameter \n\\rho\n is used as the step size \n\\alpha^k\n, campared to standard dual ascent.\n\n\n\nL(x^*,y^k) \\ \\& \\  L(x^{k+1},y^*) \\Longrightarrow \\ L(x^*,y^*)\n\n\nThe \nmethod of multipiers\n converges under far more general conditions than dual ascent, including cases when \nf\n takes on the value \n+\\infty\n or is not strictly convex. \n\n\nFor simplicity, we assume \nf\n is differentiable, though this is not required for the algorithm to work. The optimality conditions for (2.1) are primal and dual feasibility, \n\n\nAx^*-b=0, \\ \\ \\ \\ \\ \\  \\nabla f(x^*)+A^Ty^*=0 \n\n\nSince \n\n\n\\begin{align}\n\\nabla_xL_\\rho &= \\nabla_x(f(x)+y^T(Ax-b)+\\frac{\\rho}{2}\\|Ax-b\\|^2_2) \\\\&= \\nabla_xf(x)+A^Ty+\\rho A^TAx-\\rho A^Tb\\\\&=\\nabla_xf(x)+A^T(y+\\rho(Ax-b))\n\\end{align}\n\n\n By definition, \nx^{k+1}\n minimizes \nL_\\rho(x,y^k)\n, so \n\n\n\\begin{align}\n0&=\\nabla_xL_\\rho(x^{k+1,y^k}) \\\\ \n&=\\nabla_xf(x^{k+1})+A^T(y^k+\\rho(Ax^{k+1}-b)) \\\\\n&=\\nabla_xf(x^{k+1})+A^Ty^{k+1} \\\\\n&\\Rightarrow \\nabla_xf(x^*)+A^Ty^*\n\\end{align}\n\n\nBy using \n\\rho\n as the step size in the dual update, the iterate \n(x^{k+1},y^{k+1})\n is dual feasible. The primal residual \nAx^{k+1}-b\n converges to zero as the method of multipliers proceeds, yielding optimality. \n\n\nWhen \nf\n is separable, the augmented Lagrangian \nL_\\rho\n is not separable, so the \nx\n-minimization step (2.7) cannot be carried out separately in parallel for each \nx_i\n. This means that the basic methos of multipliers cannot be uesd for decomposition. \n\n\nSummary\n\n\nAdvantages: Not strict with \nf(x)\n; good converge property\n\n\nDisadvantages: distributed", 
            "title": "Augmented Lagrangians and the Method of Multipliers"
        }, 
        {
            "location": "/Augmented Lagrangians and the Method of Multipliers/#augmented-lagrangians-and-the-method-of-multipliers", 
            "text": "Purpose: bring  robustness  to the dual ascent method, and in particular, to yield convergence without assumptions like strict convexity or finiteness of  f .   The  augmented Lagrangians  is: \nL_{\\rho}(x,y)=f(x)+y^T(Ax-b)+(\\rho/2)\\|Ax-b\\|^2_2,\\tag{2.6} \nwhere  \\rho>0  is called the  penalty parameter . We can view this problem as adding a norm2 penalty term to Lagrangian. It can also be viewed as the (unaugmented) Lagrangian asscociated with the problem \n\\mbox{minimize} \\ \\ \\ f(x)+(\\rho/2)\\|Ax=b\\|^2_2\\\\  \\mbox{subject to  } \\ Ax=b \\ \\  \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \nThis part is highly related to proximal algorithm. The associated dual function is  g_p(y)=\\inf_{x} L_{\\rho}(x,y) .   The benefit of including the penalty term ( (\\rho/2)\\|Ax=b\\|^2_2\u200b ) is that  g_\\rho\u200b    can be shown to be differentiable under rather mild conditions on the original problem.   Applying the dual ascent to the modified problem: \n\\begin{align}\nx^{k+1}&:=arg\\min\\limits_{x}L_\\rho(x,y^{k})\\tag{2.7}\\\\\ny^{k+1}&:=y^{k}+\\rho(Ax^{k+1}-b),\\tag{2.8}\n\\end{align} \nwhich is known as the  method of multipiers  for solving (2.1). The  x -minimization step uses the augmented Lagrangian, and the penalty parameter  \\rho  is used as the step size  \\alpha^k , campared to standard dual ascent.  \nL(x^*,y^k) \\ \\& \\  L(x^{k+1},y^*) \\Longrightarrow \\ L(x^*,y^*) \nThe  method of multipiers  converges under far more general conditions than dual ascent, including cases when  f  takes on the value  +\\infty  or is not strictly convex.   For simplicity, we assume  f  is differentiable, though this is not required for the algorithm to work. The optimality conditions for (2.1) are primal and dual feasibility,  \nAx^*-b=0, \\ \\ \\ \\ \\ \\  \\nabla f(x^*)+A^Ty^*=0  \nSince  \n\\begin{align}\n\\nabla_xL_\\rho &= \\nabla_x(f(x)+y^T(Ax-b)+\\frac{\\rho}{2}\\|Ax-b\\|^2_2) \\\\&= \\nabla_xf(x)+A^Ty+\\rho A^TAx-\\rho A^Tb\\\\&=\\nabla_xf(x)+A^T(y+\\rho(Ax-b))\n\\end{align} \n By definition,  x^{k+1}  minimizes  L_\\rho(x,y^k) , so  \n\\begin{align}\n0&=\\nabla_xL_\\rho(x^{k+1,y^k}) \\\\ \n&=\\nabla_xf(x^{k+1})+A^T(y^k+\\rho(Ax^{k+1}-b)) \\\\\n&=\\nabla_xf(x^{k+1})+A^Ty^{k+1} \\\\\n&\\Rightarrow \\nabla_xf(x^*)+A^Ty^*\n\\end{align} \nBy using  \\rho  as the step size in the dual update, the iterate  (x^{k+1},y^{k+1})  is dual feasible. The primal residual  Ax^{k+1}-b  converges to zero as the method of multipliers proceeds, yielding optimality.   When  f  is separable, the augmented Lagrangian  L_\\rho  is not separable, so the  x -minimization step (2.7) cannot be carried out separately in parallel for each  x_i . This means that the basic methos of multipliers cannot be uesd for decomposition.", 
            "title": "Augmented Lagrangians and the Method of Multipliers"
        }, 
        {
            "location": "/Augmented Lagrangians and the Method of Multipliers/#summary", 
            "text": "Advantages: Not strict with  f(x) ; good converge property  Disadvantages: distributed", 
            "title": "Summary"
        }
    ]
}