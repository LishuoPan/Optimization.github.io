{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Optimization\n\n\nIt is a tutorial for optimization methods. \n\n\nDual Ascent\n\n\n\n\nDual Ascent\n - \n\n\nDual Decomposition\n -\n\n\n\n\nAugmented Lagrangians and the Method of Multipliers", 
            "title": "Introduciton"
        }, 
        {
            "location": "/#welcome-to-optimization", 
            "text": "It is a tutorial for optimization methods.", 
            "title": "Welcome to Optimization"
        }, 
        {
            "location": "/#dual-ascent", 
            "text": "Dual Ascent  -   Dual Decomposition  -", 
            "title": "Dual Ascent"
        }, 
        {
            "location": "/#augmented-lagrangians-and-the-method-of-multipliers", 
            "text": "", 
            "title": "Augmented Lagrangians and the Method of Multipliers"
        }, 
        {
            "location": "/dual_ascent/", 
            "text": "Dual Ascent\n\n\nProblem to solve:\n\n\n\\begin{equation}\n\\mbox{minimize} \\ \\ f(x) \\\\\n\\mbox{subject  to} \\ \\ Ax=b  \\tag{2.1}\n\\\\x\\ \\in\\ \\mathbb{R}^{n} \\ where \\ A\\  \\in\\  \\mathbb{R}^{m\\times n}\\ and\\ f:\\mathbb{R}^{n} \\rightarrow \\mathbb{R}\\ is\\ convex\n\\end{equation}\n\n\n\n\n\nThe Lagrangian for (2.1) is:\n\n\nL(x,y)=f(x)+y^{T}(Ax-b) \n\n\nThe dual function is:\n\n\ng(y) =\\inf\\limits_{x} L(x,y)=-f^{\\ast}(-A^{T}y)-b^{T}y\n\n\nwhere \ny\n is the dual variable or Lagrange multiplier, and the \nf^*\n is the conjugate of the \nf\n. This function says taht \ng(y)\n is convex of \ny\n.\n\n\nThe definition of \nf^{*}(y) \n:\n\n\nf^{*}(y):\\sup\\limits_{x\\in domf}:(y^{T}x-f(x))\n\n\n\n\\color{blue}{Proof}\n:\n\n\n\\begin{align}\ng(y) &= \\inf\\limits_{x} L(x,y)=\\inf\\limits_{x}f(x) +y^{T}Ax-y^{T}b\\\\&=-\\sup\\limits_{x}-f(x)+y^{T}(-Ax)+y^{T}b\\\\&=-f^{*}(-A^{T}y)-y^{T}b\n\\end{align}\n\n\nNow, the dual problem is \n\n\n\\mbox{maximize} \\ g(y)\n\n\nwith variable \ny\\in \\mathbb{R}^{m}\n.\n\n\nAssuming the strong duality holds. the optimal values of the primal and dual problems are the same.\n\n\nThe primal optimal point \nx^{*}\n form a dual optimal point \ny^{*}\n as \n\n\nx^{*}=arg\\min\\limits_{x} L(x,y^{*}),\n\n\nprovided that there is only one minimizer of \nL(x,y^{*})\n. \n\n\nThe notation \n\\mbox{argmin}_{x}F(x)\n denotes any minimizer of \nF\n. \n\n\nIn the \ndual\\ ascent\\ method\n, we use \ngreadient ascent\n to solve dual problem. Assuming \ng\n is differentiable. We first find \nx^{+}=argmin_{x}L(x,y)\n, then the gradient \n\\nabla g(y)=Ax^{+}-b\n, which is the residual for the equality constraint. \n\n\n\\begin{align}\nx^{k+1}&:=arg\\min\\limits_{x}L(x,y^{k})\\tag{2.2}\\\\\ny^{k+1}&:=y^{k}+\\alpha^{k}(Ax^{k+1}-b),\\tag{2.3}\n\\end{align}\n\n\nwhere \n\\alpha^{k}>0\n is a step size, the \nk\n is the iteration counter. With appropriate choice of \n\\alpha^{k}\n, \ng(y^{k+1})>g(y^{k})\n. \n\n\nThe principle is \n\\max\\limits_{y}g(y)=\\max\\limits_{x}L(x,y) \n, optimizing x and y alternatively to reach \nL(x^{*},y^{*})\n. \n\n\nWhen \ng\n is not differentiable\n\n\nThe residual \nAx^{k+1}-b\n is not the gradient of \ng\n, but the negative of a subgradient of \n-g\n.  It is often that \ng(y^{k+1})\\ngtr g(y^{k})\n. The algorithm is usually called the \ndual\\ subgradient\\ method\n. \n\n\nIf \n\\alpha^{k}\n is chosen appropriately and several other assumptions hold, then \nx^{k}\n converges to an optimal point and \ny^{k}\n converges to an opotimal dual point. \n\n\nHowever, these assumptions \ndo not hold\n in many cases. For example,  if \nf\n is a nonzero affine function of any component of x, \nL\n is unbounded below in \nx\n for most \ny\n. \n\n\nDual Decomposition\n\n\nThe \n\\color{blue}{\\mbox{major benefit}}\n of the dual ascent is that it can lead to a decentralized algorithm in some cases.\n\n\nSuppose, \nf\n is \nseparable\n, meaning that\n\n\nf(x)=\\sum_{i=1}^{N}f_{i}(x_i),\n\n\nwhere \nx=(x_1,\u2026,x_N)\n and the variables \nx_i\\in\\mathbb{R}^{n_i}\n are subvectors of \nx\n. \n\n\nPartitioning the matrix \nA\n conformably as \n\n\nA=[A_1\\cdot\\cdot\\cdot A_N],\n\n\nso \nAx=\\sum_{i=1}^{N}A_ix_i\n, the Lagrangian is \n\n\nL(x,y )=\\sum_{i=1}^{N}L_{i}(x_i,y)=\\sum_{i=1}^{N}(f_{i}+y^TA_ix_i-(1/N)y^Tb)\\\\\\mbox{such that } L(x,y)=f(x)+y^{T}(Ax-b)\n\n\nwhich is also separable in \nx\n. \n\\color{blue}{\\mbox{The x-minimization step splits into N separate prolems that can be solved in parallel.}}\n\n\n\n\nNow, the algorithm is \n\n\n\\begin{align}\nx^{k+1}_i&:=arg\\min\\limits_{x_i}L_i(x_i,y^k)\\tag{2.4}\\\\\ny^{k+1}&:=y^k+\\alpha^{k}(Ax^{k+1}-b).\\tag{2.5}\n\\end{align}\n\n\nIn this case, we refer to the dual ascent mehtod as \ndual decomposition\n. Dual decomposition is used to do dual acent method for separable \nf(x)\n. Dual decomposition is distributed dual ascent method. \n\n\nImplementation\n\n\nEach iteration of the dual decomposition methods inclued \nbroadcast\n and \ngather\n operation.  First, \nA_ix_i^{k+1}\n are collected(gathered). Second, compute the residual \nAx^{k+1}-b\n.  Then, compute the (global) dual variable \ny^{k+1}\n. Finally, distributed (broadcast)  to the processors that carry out the \nN\n individual \nx_i\n minimization steps (2.4). \n\n\nSummary\n\n\nAdvantages: \n\n\nDisadvantages:", 
            "title": "Daul Ascent"
        }, 
        {
            "location": "/dual_ascent/#dual-ascent", 
            "text": "Problem to solve: \n\\begin{equation}\n\\mbox{minimize} \\ \\ f(x) \\\\\n\\mbox{subject  to} \\ \\ Ax=b  \\tag{2.1}\n\\\\x\\ \\in\\ \\mathbb{R}^{n} \\ where \\ A\\  \\in\\  \\mathbb{R}^{m\\times n}\\ and\\ f:\\mathbb{R}^{n} \\rightarrow \\mathbb{R}\\ is\\ convex\n\\end{equation}   The Lagrangian for (2.1) is: \nL(x,y)=f(x)+y^{T}(Ax-b)  \nThe dual function is: \ng(y) =\\inf\\limits_{x} L(x,y)=-f^{\\ast}(-A^{T}y)-b^{T}y \nwhere  y  is the dual variable or Lagrange multiplier, and the  f^*  is the conjugate of the  f . This function says taht  g(y)  is convex of  y .  The definition of  f^{*}(y)  : \nf^{*}(y):\\sup\\limits_{x\\in domf}:(y^{T}x-f(x))  \\color{blue}{Proof} : \n\\begin{align}\ng(y) &= \\inf\\limits_{x} L(x,y)=\\inf\\limits_{x}f(x) +y^{T}Ax-y^{T}b\\\\&=-\\sup\\limits_{x}-f(x)+y^{T}(-Ax)+y^{T}b\\\\&=-f^{*}(-A^{T}y)-y^{T}b\n\\end{align} \nNow, the dual problem is  \n\\mbox{maximize} \\ g(y) \nwith variable  y\\in \\mathbb{R}^{m} .  Assuming the strong duality holds. the optimal values of the primal and dual problems are the same.  The primal optimal point  x^{*}  form a dual optimal point  y^{*}  as  \nx^{*}=arg\\min\\limits_{x} L(x,y^{*}), \nprovided that there is only one minimizer of  L(x,y^{*}) .   The notation  \\mbox{argmin}_{x}F(x)  denotes any minimizer of  F .   In the  dual\\ ascent\\ method , we use  greadient ascent  to solve dual problem. Assuming  g  is differentiable. We first find  x^{+}=argmin_{x}L(x,y) , then the gradient  \\nabla g(y)=Ax^{+}-b , which is the residual for the equality constraint.  \n\\begin{align}\nx^{k+1}&:=arg\\min\\limits_{x}L(x,y^{k})\\tag{2.2}\\\\\ny^{k+1}&:=y^{k}+\\alpha^{k}(Ax^{k+1}-b),\\tag{2.3}\n\\end{align} \nwhere  \\alpha^{k}>0  is a step size, the  k  is the iteration counter. With appropriate choice of  \\alpha^{k} ,  g(y^{k+1})>g(y^{k}) .   The principle is  \\max\\limits_{y}g(y)=\\max\\limits_{x}L(x,y)  , optimizing x and y alternatively to reach  L(x^{*},y^{*}) .", 
            "title": "Dual Ascent"
        }, 
        {
            "location": "/dual_ascent/#when-g-is-not-differentiable", 
            "text": "The residual  Ax^{k+1}-b  is not the gradient of  g , but the negative of a subgradient of  -g .  It is often that  g(y^{k+1})\\ngtr g(y^{k}) . The algorithm is usually called the  dual\\ subgradient\\ method .   If  \\alpha^{k}  is chosen appropriately and several other assumptions hold, then  x^{k}  converges to an optimal point and  y^{k}  converges to an opotimal dual point.   However, these assumptions  do not hold  in many cases. For example,  if  f  is a nonzero affine function of any component of x,  L  is unbounded below in  x  for most  y .", 
            "title": "When g is not differentiable"
        }, 
        {
            "location": "/dual_ascent/#dual-decomposition", 
            "text": "The  \\color{blue}{\\mbox{major benefit}}  of the dual ascent is that it can lead to a decentralized algorithm in some cases.  Suppose,  f  is  separable , meaning that \nf(x)=\\sum_{i=1}^{N}f_{i}(x_i), \nwhere  x=(x_1,\u2026,x_N)  and the variables  x_i\\in\\mathbb{R}^{n_i}  are subvectors of  x .   Partitioning the matrix  A  conformably as  \nA=[A_1\\cdot\\cdot\\cdot A_N], \nso  Ax=\\sum_{i=1}^{N}A_ix_i , the Lagrangian is  \nL(x,y )=\\sum_{i=1}^{N}L_{i}(x_i,y)=\\sum_{i=1}^{N}(f_{i}+y^TA_ix_i-(1/N)y^Tb)\\\\\\mbox{such that } L(x,y)=f(x)+y^{T}(Ax-b) \nwhich is also separable in  x .  \\color{blue}{\\mbox{The x-minimization step splits into N separate prolems that can be solved in parallel.}}   Now, the algorithm is  \n\\begin{align}\nx^{k+1}_i&:=arg\\min\\limits_{x_i}L_i(x_i,y^k)\\tag{2.4}\\\\\ny^{k+1}&:=y^k+\\alpha^{k}(Ax^{k+1}-b).\\tag{2.5}\n\\end{align} \nIn this case, we refer to the dual ascent mehtod as  dual decomposition . Dual decomposition is used to do dual acent method for separable  f(x) . Dual decomposition is distributed dual ascent method.", 
            "title": "Dual Decomposition"
        }, 
        {
            "location": "/dual_ascent/#implementation", 
            "text": "Each iteration of the dual decomposition methods inclued  broadcast  and  gather  operation.  First,  A_ix_i^{k+1}  are collected(gathered). Second, compute the residual  Ax^{k+1}-b .  Then, compute the (global) dual variable  y^{k+1} . Finally, distributed (broadcast)  to the processors that carry out the  N  individual  x_i  minimization steps (2.4).", 
            "title": "Implementation"
        }, 
        {
            "location": "/dual_ascent/#summary", 
            "text": "Advantages:   Disadvantages:", 
            "title": "Summary"
        }, 
        {
            "location": "/Augmented Lagrangians and the Method of Multipliers/", 
            "text": "Augmented Lagrangians and the Method of Multipliers\n\n\nPurpose: bring \nrobustness\n to the dual ascent method, and in particular, to yield convergence without assumptions like strict convexity or finiteness of \nf\n. \n\n\nThe \naugmented Lagrangians\n is:\n\n\nL_{\\rho}(x,y)=f(x)+y^T(Ax-b)+(\\rho/2)\\|Ax-b\\|^2_2,\\tag{2.6}\n\n\nwhere \n\\rho>0\n is called the \npenalty parameter\n. We can view this problem as adding a norm2 penalty term to Lagrangian. It can also be viewed as the (unaugmented) Lagrangian asscociated with the problem\n\n\n\\mbox{minimize} \\ \\ \\ f(x)+(\\rho/2)\\|Ax=b\\|^2_2\\\\  \\mbox{subject to  } \\ Ax=b \\ \\  \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n\n\nThis part is highly related to proximal algorithm. The associated dual function is \ng_p(y)=\\inf_{x} L_{\\rho}(x,y)\n. \n\n\nThe benefit of including the penalty term (\n(\\rho/2)\\|Ax=b\\|^2_2\u200b\n) is that \ng_\\rho\u200b\n   can be shown to be differentiable under rather mild conditions on the original problem. \n\n\nApplying the dual ascent to the modified problem:\n\n\n\\begin{align}\nx^{k+1}&:=arg\\min\\limits_{x}L_\\rho(x,y^{k})\\tag{2.7}\\\\\ny^{k+1}&:=y^{k}+\\rho(Ax^{k+1}-b),\\tag{2.8}\n\\end{align}\n\n\nwhich is known as the \nmethod of multipiers\n for solving (2.1). The \nx\n-minimization step uses the augmented Lagrangian, and the penalty parameter \n\\rho\n is used as the step size \n\\alpha^k\n, campared to standard dual ascent.\n\n\n\nL(x^*,y^k) \\ \\& \\  L(x^{k+1},y^*) \\Longrightarrow \\ L(x^*,y^*)\n\n\nThe \nmethod of multipiers\n converges under far more general conditions than dual ascent, including cases when \nf\n takes on the value \n+\\infty\n or is not strictly convex. \n\n\nFor simplicity, we assume \nf\n is differentiable, though this is not required for the algorithm to work. The optimality conditions for (2.1) are primal and dual feasibility, \n\n\nAx^*-b=0, \\ \\ \\ \\ \\ \\  \\nabla f(x^*)+A^Ty^*=0 \n\n\nSince \n\n\n\\begin{align}\n\\nabla_xL_\\rho &= \\nabla_x(f(x)+y^T(Ax-b)+\\frac{\\rho}{2}\\|Ax-b\\|^2_2) \\\\&= \\nabla_xf(x)+A^Ty+\\rho A^TAx-\\rho A^Tb\\\\&=\\nabla_xf(x)+A^T(y+\\rho(Ax-b))\n\\end{align}\n\n\n By definition, \nx^{k+1}\n minimizes \nL_\\rho(x,y^k)\n, so \n\n\n\\begin{align}\n0&=\\nabla_xL_\\rho(x^{k+1,y^k}) \\\\ \n&=\\nabla_xf(x^{k+1})+A^T(y^k+\\rho(Ax^{k+1}-b)) \\\\\n&=\\nabla_xf(x^{k+1})+A^Ty^{k+1} \\\\\n&\\Rightarrow \\nabla_xf(x^*)+A^Ty^*\n\\end{align}\n\n\nBy using \n\\rho\n as the step size in the dual update, the iterate \n(x^{k+1},y^{k+1})\n is dual feasible. The primal residual \nAx^{k+1}-b\n converges to zero as the method of multipliers proceeds, yielding optimality. \n\n\nWhen \nf\n is separable, the augmented Lagrangian \nL_\\rho\n is not separable, so the \nx\n-minimization step (2.7) cannot be carried out separately in parallel for each \nx_i\n. This means that the basic methos of multipliers cannot be uesd for decomposition. \n\n\nSummary\n\n\nAdvantages: Not strict with \nf(x)\n; good converge property\n\n\nDisadvantages: distributed", 
            "title": "Augmented Lagrangians and the Method of Multipliers"
        }, 
        {
            "location": "/Augmented Lagrangians and the Method of Multipliers/#augmented-lagrangians-and-the-method-of-multipliers", 
            "text": "Purpose: bring  robustness  to the dual ascent method, and in particular, to yield convergence without assumptions like strict convexity or finiteness of  f .   The  augmented Lagrangians  is: \nL_{\\rho}(x,y)=f(x)+y^T(Ax-b)+(\\rho/2)\\|Ax-b\\|^2_2,\\tag{2.6} \nwhere  \\rho>0  is called the  penalty parameter . We can view this problem as adding a norm2 penalty term to Lagrangian. It can also be viewed as the (unaugmented) Lagrangian asscociated with the problem \n\\mbox{minimize} \\ \\ \\ f(x)+(\\rho/2)\\|Ax=b\\|^2_2\\\\  \\mbox{subject to  } \\ Ax=b \\ \\  \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \nThis part is highly related to proximal algorithm. The associated dual function is  g_p(y)=\\inf_{x} L_{\\rho}(x,y) .   The benefit of including the penalty term ( (\\rho/2)\\|Ax=b\\|^2_2\u200b ) is that  g_\\rho\u200b    can be shown to be differentiable under rather mild conditions on the original problem.   Applying the dual ascent to the modified problem: \n\\begin{align}\nx^{k+1}&:=arg\\min\\limits_{x}L_\\rho(x,y^{k})\\tag{2.7}\\\\\ny^{k+1}&:=y^{k}+\\rho(Ax^{k+1}-b),\\tag{2.8}\n\\end{align} \nwhich is known as the  method of multipiers  for solving (2.1). The  x -minimization step uses the augmented Lagrangian, and the penalty parameter  \\rho  is used as the step size  \\alpha^k , campared to standard dual ascent.  \nL(x^*,y^k) \\ \\& \\  L(x^{k+1},y^*) \\Longrightarrow \\ L(x^*,y^*) \nThe  method of multipiers  converges under far more general conditions than dual ascent, including cases when  f  takes on the value  +\\infty  or is not strictly convex.   For simplicity, we assume  f  is differentiable, though this is not required for the algorithm to work. The optimality conditions for (2.1) are primal and dual feasibility,  \nAx^*-b=0, \\ \\ \\ \\ \\ \\  \\nabla f(x^*)+A^Ty^*=0  \nSince  \n\\begin{align}\n\\nabla_xL_\\rho &= \\nabla_x(f(x)+y^T(Ax-b)+\\frac{\\rho}{2}\\|Ax-b\\|^2_2) \\\\&= \\nabla_xf(x)+A^Ty+\\rho A^TAx-\\rho A^Tb\\\\&=\\nabla_xf(x)+A^T(y+\\rho(Ax-b))\n\\end{align} \n By definition,  x^{k+1}  minimizes  L_\\rho(x,y^k) , so  \n\\begin{align}\n0&=\\nabla_xL_\\rho(x^{k+1,y^k}) \\\\ \n&=\\nabla_xf(x^{k+1})+A^T(y^k+\\rho(Ax^{k+1}-b)) \\\\\n&=\\nabla_xf(x^{k+1})+A^Ty^{k+1} \\\\\n&\\Rightarrow \\nabla_xf(x^*)+A^Ty^*\n\\end{align} \nBy using  \\rho  as the step size in the dual update, the iterate  (x^{k+1},y^{k+1})  is dual feasible. The primal residual  Ax^{k+1}-b  converges to zero as the method of multipliers proceeds, yielding optimality.   When  f  is separable, the augmented Lagrangian  L_\\rho  is not separable, so the  x -minimization step (2.7) cannot be carried out separately in parallel for each  x_i . This means that the basic methos of multipliers cannot be uesd for decomposition.", 
            "title": "Augmented Lagrangians and the Method of Multipliers"
        }, 
        {
            "location": "/Augmented Lagrangians and the Method of Multipliers/#summary", 
            "text": "Advantages: Not strict with  f(x) ; good converge property  Disadvantages: distributed", 
            "title": "Summary"
        }, 
        {
            "location": "/ADMM/", 
            "text": "3.1 Algorithm\n\n\nIt is an algorithm intended to blend the decomposability of dual ascent with the superior convergence properties of the method of multipliers. \n\n\n\\begin{align}\n\\mbox{minimize} \\ &f(x)+g(z) \\tag{3.1} \\\\\n\\mbox{subject to} \\ &Ax+Bz=c\n\\end{align}\n\n\nwith variables \nx\\in\\mathbb{R}^m \n and \nz\\in \\mathbb{R}^m\n, where \nA\\in \\mathbb{R}^{p\\times n},\\ B\\in{R}^{p\\times m}\n, and \nc\\in\\mathbb{R}^p\n. We assume \nf\n and \ng\n are convex. The difference from general linear equality-constrained problem (2.1) is \nx\n has been split into two parts, called \nx\n and \nz\n here, with the objective functions \nseparable\n across splitting. \n\n\nThe optimal value of (3.1) denoted by\n\n\np^*=\\inf \\{f(x)+g(z)|Ax+Bz=c\\}.\n\n\nWe form the \naugmented Lagrangian\n \n\n\nL_0(x,z,y)=f(x)+g(z)+y^T(Ax+Bz-c)\\\\\nL\\rho(x,z,y)=f(x)+g(z)+y^T(Ax+Bz-c)+(\\rho/2)\\|Ax+Bz-c\\|^2_2.\n\n\nThe \niterations of ADMM\n (unscaled form) is \n\n\n\\begin{align}\nx\\mbox{-minimization step: }  x^{k+1}&:=arg\\min_x L_\\rho (x,z^k,y^k)  \\tag{3.2}  \\\\\nz\\mbox{-minimization step: }z^{k+1}&:=arg\\min_xL_\\rho(x^{k+1},z,y^k) \\tag{3.3}\\\\\n\\mbox{Dual variable update: }y^{k+1}&:=y^k+\\rho(Ax^{k+1}+Bz^{k+1}-c)\\tag{3.4}\n\\end{align}\n\n\nwhere \n\\rho>0\n, \nAx+Bz-c\n is gradient. \n\\rho\n is the step size. Our target is to find \nL(x^*,z^*,y^*)\n. \n\n\nDifferent from (3.2), (3.3), (3,4), the following form is minimized \njointly\n with respect to the two primal variables. The method of multipliers for (3.1) has the form\n\n\n\\begin{align}\n(x^{k+1},z^{k+1})&:=arg\\min_{x,z}L_\\rho(x,z,y^{k})\\\\\ny^{k+1}&:=y^k+\\rho(Ax^{k+1}+Bz{k+1}-c)\n\\end{align}\n\n\n\n3.1.1 Scale Form\n\n\nADMM can be written in a slightly different form, which is often more convevient. Defining the residual \nr=Ax+Bz-c\n, we have\n\n\n\\begin{align}\ny^Tr+(\\rho/2)\\|r\\|^2_2 &=(\\rho/2)\\|r+(1/\\rho)y\\|^2_2-(1/2\\rho)\\|y\\|^2_2\\\\\n&=(\\rho/2)\\|r+u\\|^2_2-(\\rho/2)\\|u\\|^2_2,\n\\end{align}\n\n\nwhere \nu=(1/\\rho)y\n is the \nscaled dual variable.\n The \naugmented Lagrangian\n is\n\n\nL_\\rho=f(x)+g(z)+(\\rho/2)\\|r+u\\|^2_2-(\\rho/2)\\|u\\|^2_2\n\n\n It is the same as unscaled form.\n\n\n\n\n\\color{blue}{Proof}\n:\n\n\n\\begin{align}\n(\\rho/2)\\|r+u\\|^2_2 &=(\\rho/2)\\|Ax+Bz-c+\\frac{1}{\\rho}y\\|^2_2\\\\\n&=(\\rho/2)\\left[\\|Ax+Bz-c\\|^2_2+(\\rho/2)y^T(Ax+Bz-c)+\\frac{1}{\\rho^2}\\|y\\|^2_2\\right]\\\\\n&=(\\rho/2)\\|Ax+Bz-c\\|^2_2+y^T(Ax+Bz-c)+(1/2\\rho)\\|y\\|^2_2\\\\ \\\\ \n(\\rho/2)\\|u\\|^2_2 &=(\\rho/2)\\times(1/\\rho^2)\\|y\\|^2_2\\\\\n&=\\frac{1}{2\\rho}\\|y\\|^2_2\\\n\\end{align}\n\n\n\nADMM(scaled)\n  can be expressed as\n\n\n\\begin{align}\nx\\mbox{-minimization step: }  x^{k+1}&:=arg\\min_x (  f(x)+(\\rho/2)\\|Ax+Bz^k-c+u^k\\|^2_2 )\\tag{3.5}  \\\\\nz\\mbox{-minimization step: }z^{k+1}&:=arg\\min_z (  g(z)+(\\rho/2)\\|Ax^{k+1}+Bz-c+u^k\\|^2_2 )\\tag{3.6}\\\\\n\\mbox{Dual variable update: }u^{k+1}&:=u^k+Ax^{k+1}+B^{k+1}-c.\\tag{3.7}\n\\end{align}\n\n\nDefining the residual at iteration \nk\n as \nr^k=Ax^k+Bz^k-c\n, we see that \n\n\nu^k=u^0+\\sum_{j=1}^{k} r^j\n\n\nthe running sum of the residuals. \n\n\nWe use the unscaled form when we wish to emphasize the role of the dual variable or to give an interpretation thet relies on the (unscaled) dual variable. \n\n\nConvergence\n\n\nAssumpition 1\n: The (extended-real-valued) funcitons \nf\n: \n\\mathbb{R}^n\\rightarrow\\mathbb{R}\\cup \\{+\\infty\\}\n and \ng:\\mathbb{R}^m\\rightarrow\\mathbb{R}\\cup\\{+\\infty\\}\n are close, proper, and convex.\n\n\nThe funciton satisfies as.1 if and only if its epigraph \n\n\n\\textbf{epi} \\ f=\\{(x,t)\\in\\mathbb{R}^n\\times\\mathbb{R}|f(x)\\leq t\\}\n\n\nis a closed nonempty convex set.\n\n\nAssumption 1 allows \nf\n and \ng\n to be nondifferentiable and to assume the value \n+\\infty\n. We can take \nf\n to be \nthe indicator function\n of a closed nonempty convex set \nC\n, \n\n\n\\begin{equation}  \nf(x) = \n\\left\\{  \n             \\begin{array}{lr}  \n             1,  \\mbox{for } x\\in C   \\\\ \n           +\\infty,     \\mbox{otherwise}\n             \\end{array}  \n\\right.  \n\\end{equation}\n\n\nIn this case, the \nx\n-minimization step (3.2) will involve solving a constrained quadratic program over \nC\n, the effective domain of \nf\n. \n\n\nAssumption 2\n: The unaugmented Lagrangian \nL_0\n has a saddle point.\n\n\nThere exists \n(x^*,z^*,y^*)\n, not necessarily unique, for which\n\n\nL_0(x^*,z^*,y)\\leq L_0(x^*,z^*,y^*)\\leq L_0(x,z,y^*)\n\n\nholds for all \nx,z,y\n. \n\n\n\n\nL_0(x^*,z^*,y^*)\n is finite for any saddle point \n(x^*,z^*,y^*)\n. This implies that \n(x^*,z^*)\n is a solution to (3.1), so \nAx^*+Bz^*=c\n and \nf(x^*)<\\infty,g(z^*)<\\infty\n. It also implies that strong duality holds. \n\n\n3.2.1 Convergence", 
            "title": "Alternating Direciton of Multipliers"
        }, 
        {
            "location": "/ADMM/#31-algorithm", 
            "text": "It is an algorithm intended to blend the decomposability of dual ascent with the superior convergence properties of the method of multipliers.  \n\\begin{align}\n\\mbox{minimize} \\ &f(x)+g(z) \\tag{3.1} \\\\\n\\mbox{subject to} \\ &Ax+Bz=c\n\\end{align} \nwith variables  x\\in\\mathbb{R}^m   and  z\\in \\mathbb{R}^m , where  A\\in \\mathbb{R}^{p\\times n},\\ B\\in{R}^{p\\times m} , and  c\\in\\mathbb{R}^p . We assume  f  and  g  are convex. The difference from general linear equality-constrained problem (2.1) is  x  has been split into two parts, called  x  and  z  here, with the objective functions  separable  across splitting.   The optimal value of (3.1) denoted by \np^*=\\inf \\{f(x)+g(z)|Ax+Bz=c\\}. \nWe form the  augmented Lagrangian   \nL_0(x,z,y)=f(x)+g(z)+y^T(Ax+Bz-c)\\\\\nL\\rho(x,z,y)=f(x)+g(z)+y^T(Ax+Bz-c)+(\\rho/2)\\|Ax+Bz-c\\|^2_2. \nThe  iterations of ADMM  (unscaled form) is  \n\\begin{align}\nx\\mbox{-minimization step: }  x^{k+1}&:=arg\\min_x L_\\rho (x,z^k,y^k)  \\tag{3.2}  \\\\\nz\\mbox{-minimization step: }z^{k+1}&:=arg\\min_xL_\\rho(x^{k+1},z,y^k) \\tag{3.3}\\\\\n\\mbox{Dual variable update: }y^{k+1}&:=y^k+\\rho(Ax^{k+1}+Bz^{k+1}-c)\\tag{3.4}\n\\end{align} \nwhere  \\rho>0 ,  Ax+Bz-c  is gradient.  \\rho  is the step size. Our target is to find  L(x^*,z^*,y^*) .   Different from (3.2), (3.3), (3,4), the following form is minimized  jointly  with respect to the two primal variables. The method of multipliers for (3.1) has the form \n\\begin{align}\n(x^{k+1},z^{k+1})&:=arg\\min_{x,z}L_\\rho(x,z,y^{k})\\\\\ny^{k+1}&:=y^k+\\rho(Ax^{k+1}+Bz{k+1}-c)\n\\end{align}  3.1.1 Scale Form  ADMM can be written in a slightly different form, which is often more convevient. Defining the residual  r=Ax+Bz-c , we have \n\\begin{align}\ny^Tr+(\\rho/2)\\|r\\|^2_2 &=(\\rho/2)\\|r+(1/\\rho)y\\|^2_2-(1/2\\rho)\\|y\\|^2_2\\\\\n&=(\\rho/2)\\|r+u\\|^2_2-(\\rho/2)\\|u\\|^2_2,\n\\end{align} \nwhere  u=(1/\\rho)y  is the  scaled dual variable.  The  augmented Lagrangian  is \nL_\\rho=f(x)+g(z)+(\\rho/2)\\|r+u\\|^2_2-(\\rho/2)\\|u\\|^2_2 \n It is the same as unscaled form.   \\color{blue}{Proof} : \n\\begin{align}\n(\\rho/2)\\|r+u\\|^2_2 &=(\\rho/2)\\|Ax+Bz-c+\\frac{1}{\\rho}y\\|^2_2\\\\\n&=(\\rho/2)\\left[\\|Ax+Bz-c\\|^2_2+(\\rho/2)y^T(Ax+Bz-c)+\\frac{1}{\\rho^2}\\|y\\|^2_2\\right]\\\\\n&=(\\rho/2)\\|Ax+Bz-c\\|^2_2+y^T(Ax+Bz-c)+(1/2\\rho)\\|y\\|^2_2\\\\ \\\\ \n(\\rho/2)\\|u\\|^2_2 &=(\\rho/2)\\times(1/\\rho^2)\\|y\\|^2_2\\\\\n&=\\frac{1}{2\\rho}\\|y\\|^2_2\\\n\\end{align}  ADMM(scaled)   can be expressed as \n\\begin{align}\nx\\mbox{-minimization step: }  x^{k+1}&:=arg\\min_x (  f(x)+(\\rho/2)\\|Ax+Bz^k-c+u^k\\|^2_2 )\\tag{3.5}  \\\\\nz\\mbox{-minimization step: }z^{k+1}&:=arg\\min_z (  g(z)+(\\rho/2)\\|Ax^{k+1}+Bz-c+u^k\\|^2_2 )\\tag{3.6}\\\\\n\\mbox{Dual variable update: }u^{k+1}&:=u^k+Ax^{k+1}+B^{k+1}-c.\\tag{3.7}\n\\end{align} \nDefining the residual at iteration  k  as  r^k=Ax^k+Bz^k-c , we see that  \nu^k=u^0+\\sum_{j=1}^{k} r^j \nthe running sum of the residuals.   We use the unscaled form when we wish to emphasize the role of the dual variable or to give an interpretation thet relies on the (unscaled) dual variable.", 
            "title": "3.1 Algorithm"
        }, 
        {
            "location": "/ADMM/#convergence", 
            "text": "Assumpition 1 : The (extended-real-valued) funcitons  f :  \\mathbb{R}^n\\rightarrow\\mathbb{R}\\cup \\{+\\infty\\}  and  g:\\mathbb{R}^m\\rightarrow\\mathbb{R}\\cup\\{+\\infty\\}  are close, proper, and convex.  The funciton satisfies as.1 if and only if its epigraph  \n\\textbf{epi} \\ f=\\{(x,t)\\in\\mathbb{R}^n\\times\\mathbb{R}|f(x)\\leq t\\} \nis a closed nonempty convex set.  Assumption 1 allows  f  and  g  to be nondifferentiable and to assume the value  +\\infty . We can take  f  to be  the indicator function  of a closed nonempty convex set  C ,  \n\\begin{equation}  \nf(x) = \n\\left\\{  \n             \\begin{array}{lr}  \n             1,  \\mbox{for } x\\in C   \\\\ \n           +\\infty,     \\mbox{otherwise}\n             \\end{array}  \n\\right.  \n\\end{equation} \nIn this case, the  x -minimization step (3.2) will involve solving a constrained quadratic program over  C , the effective domain of  f .   Assumption 2 : The unaugmented Lagrangian  L_0  has a saddle point.  There exists  (x^*,z^*,y^*) , not necessarily unique, for which \nL_0(x^*,z^*,y)\\leq L_0(x^*,z^*,y^*)\\leq L_0(x,z,y^*) \nholds for all  x,z,y .    L_0(x^*,z^*,y^*)  is finite for any saddle point  (x^*,z^*,y^*) . This implies that  (x^*,z^*)  is a solution to (3.1), so  Ax^*+Bz^*=c  and  f(x^*)<\\infty,g(z^*)<\\infty . It also implies that strong duality holds.   3.2.1 Convergence", 
            "title": "Convergence"
        }
    ]
}