<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Alternating Direciton of Multipliers - Optimization</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Alternating Direciton of Multipliers";
    var mkdocs_page_input_path = "ADMM.md";
    var mkdocs_page_url = "/ADMM/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Optimization</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Introduciton</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../dual_ascent/">Daul Ascent</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../Augmented Lagrangians and the Method of Multipliers/">ADMM</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Alternating Direciton of Multipliers</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#31-algorithm">3.1 Algorithm</a></li>
    

    <li class="toctree-l2"><a href="#convergence">Convergence</a></li>
    

    <li class="toctree-l2"><a href="#optimality-conditions-and-stopping-criterion">Optimality Conditions and Stopping Criterion</a></li>
    

    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Optimization</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Alternating Direciton of Multipliers</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h5 id="31-algorithm">3.1 Algorithm</h5>
<p>It is an algorithm intended to blend the decomposability of dual ascent with the superior convergence properties of the method of multipliers. 
<script type="math/tex; mode=display">
\begin{align}
\mbox{minimize} \ &f(x)+g(z) \tag{3.1} \\
\mbox{subject to} \ &Ax+Bz=c
\end{align}
</script>
with variables <script type="math/tex">x\in\mathbb{R}^m </script> and <script type="math/tex">z\in \mathbb{R}^m</script>, where <script type="math/tex">A\in \mathbb{R}^{p\times n},\ B\in{R}^{p\times m}</script>, and <script type="math/tex">c\in\mathbb{R}^p</script>. We assume <script type="math/tex">f</script> and <script type="math/tex">g</script> are convex. The difference from general linear equality-constrained problem (2.1) is <script type="math/tex">x</script> has been split into two parts, called <script type="math/tex">x</script> and <script type="math/tex">z</script> here, with the objective functions <strong>separable</strong> across splitting. </p>
<p>The optimal value of (3.1) denoted by
<script type="math/tex; mode=display">
p^*=\inf \{f(x)+g(z)|Ax+Bz=c\}.
</script>
We form the <strong>augmented Lagrangian</strong> 
<script type="math/tex; mode=display">
L_0(x,z,y)=f(x)+g(z)+y^T(Ax+Bz-c)\\
L\rho(x,z,y)=f(x)+g(z)+y^T(Ax+Bz-c)+(\rho/2)\|Ax+Bz-c\|^2_2.
</script>
The <strong>iterations of ADMM</strong> (unscaled form) is 
<script type="math/tex; mode=display">
\begin{align}
x\mbox{-minimization step: }  x^{k+1}&:=arg\min_x L_\rho (x,z^k,y^k)  \tag{3.2}  \\
z\mbox{-minimization step: }z^{k+1}&:=arg\min_xL_\rho(x^{k+1},z,y^k) \tag{3.3}\\
\mbox{Dual variable update: }y^{k+1}&:=y^k+\rho(Ax^{k+1}+Bz^{k+1}-c)\tag{3.4}
\end{align}
</script>
where <script type="math/tex">\rho>0</script>, <script type="math/tex">Ax+Bz-c</script> is gradient. <script type="math/tex">\rho</script> is the step size. Our target is to find <script type="math/tex">L(x^*,z^*,y^*)</script>. </p>
<p>Different from (3.2), (3.3), (3,4), the following form is minimized <strong>jointly</strong> with respect to the two primal variables. The method of multipliers for (3.1) has the form
<script type="math/tex; mode=display">
\begin{align}
(x^{k+1},z^{k+1})&:=arg\min_{x,z}L_\rho(x,z,y^{k})\\
y^{k+1}&:=y^k+\rho(Ax^{k+1}+Bz{k+1}-c)
\end{align}
</script>
<strong>3.1.1 Scale Form</strong></p>
<p>ADMM can be written in a slightly different form, which is often more convevient. Defining the residual <script type="math/tex">r=Ax+Bz-c</script>, we have
<script type="math/tex; mode=display">
\begin{align}
y^Tr+(\rho/2)\|r\|^2_2 &=(\rho/2)\|r+(1/\rho)y\|^2_2-(1/2\rho)\|y\|^2_2\\
&=(\rho/2)\|r+u\|^2_2-(\rho/2)\|u\|^2_2,
\end{align}
</script>
where <script type="math/tex">u=(1/\rho)y</script> is the <em>scaled dual variable.</em> The <strong>augmented Lagrangian</strong> is
<script type="math/tex; mode=display">
L_\rho=f(x)+g(z)+(\rho/2)\|r+u\|^2_2-(\rho/2)\|u\|^2_2
</script>
 It is the same as unscaled form.</p>
<p>
<script type="math/tex">\color{blue}{Proof}</script>:
<script type="math/tex; mode=display">
\begin{align}
(\rho/2)\|r+u\|^2_2 &=(\rho/2)\|Ax+Bz-c+\frac{1}{\rho}y\|^2_2\\
&=(\rho/2)\left[\|Ax+Bz-c\|^2_2+(\rho/2)y^T(Ax+Bz-c)+\frac{1}{\rho^2}\|y\|^2_2\right]\\
&=(\rho/2)\|Ax+Bz-c\|^2_2+y^T(Ax+Bz-c)+(1/2\rho)\|y\|^2_2\\ \\ 
(\rho/2)\|u\|^2_2 &=(\rho/2)\times(1/\rho^2)\|y\|^2_2\\
&=\frac{1}{2\rho}\|y\|^2_2\
\end{align}
</script>
<strong>ADMM(scaled)</strong>  can be expressed as
<script type="math/tex; mode=display">
\begin{align}
x\mbox{-minimization step: }  x^{k+1}&:=arg\min_x (  f(x)+(\rho/2)\|Ax+Bz^k-c+u^k\|^2_2 )\tag{3.5}  \\
z\mbox{-minimization step: }z^{k+1}&:=arg\min_z (  g(z)+(\rho/2)\|Ax^{k+1}+Bz-c+u^k\|^2_2 )\tag{3.6}\\
\mbox{Dual variable update: }u^{k+1}&:=u^k+Ax^{k+1}+B^{k+1}-c.\tag{3.7}
\end{align}
</script>
Defining the residual at iteration <script type="math/tex">k</script> as <script type="math/tex">r^k=Ax^k+Bz^k-c</script>, we see that 
<script type="math/tex; mode=display">
u^k=u^0+\sum_{j=1}^{k} r^j
</script>
the running sum of the residuals. </p>
<p>We use the unscaled form when we wish to emphasize the role of the dual variable or to give an interpretation thet relies on the (unscaled) dual variable. </p>
<h5 id="convergence">Convergence</h5>
<p><strong>Assumpition 1</strong>: The (extended-real-valued) funcitons <script type="math/tex">f</script>: <script type="math/tex">\mathbb{R}^n\rightarrow\mathbb{R}\cup \{+\infty\}</script> and <script type="math/tex">g:\mathbb{R}^m\rightarrow\mathbb{R}\cup\{+\infty\}</script> are close, proper, and convex.</p>
<p>The funciton satisfies as.1 if and only if its epigraph 
<script type="math/tex; mode=display">
\textbf{epi} \ f=\{(x,t)\in\mathbb{R}^n\times\mathbb{R}|f(x)\leq t\}
</script>
is a closed nonempty convex set.</p>
<p>Assumption 1 allows <script type="math/tex">f</script> and <script type="math/tex">g</script> to be nondifferentiable and to assume the value <script type="math/tex">+\infty</script>. We can take <script type="math/tex">f</script> to be <strong>the indicator function</strong> of a closed nonempty convex set <script type="math/tex">C</script>, 
<script type="math/tex; mode=display">
\begin{equation}  
f(x) = 
\left\{  
             \begin{array}{lr}  
             1,  \mbox{for } x\in C   \\ 
           +\infty,     \mbox{otherwise}
             \end{array}  
\right.  
\end{equation}
</script>
In this case, the <script type="math/tex">x</script>-minimization step (3.2) will involve solving a constrained quadratic program over <script type="math/tex">C</script>, the effective domain of <script type="math/tex">f</script>. </p>
<p><strong>Assumption 2</strong>: The unaugmented Lagrangian <script type="math/tex">L_0</script> has a saddle point.</p>
<p>There exists <script type="math/tex">(x^*,z^*,y^*)</script>, not necessarily unique, for which
<script type="math/tex; mode=display">
L_0(x^*,z^*,y)\leq L_0(x^*,z^*,y^*)\leq L_0(x,z,y^*)
</script>
holds for all <script type="math/tex">x,z,y</script>. </p>
<p>
<script type="math/tex">L_0(x^*,z^*,y^*)</script> is finite for any saddle point <script type="math/tex">(x^*,z^*,y^*)</script>. This implies that <script type="math/tex">(x^*,z^*)</script> is a solution to (3.1), so <script type="math/tex">Ax^*+Bz^*=c</script> and <script type="math/tex">f(x^*)<\infty,g(z^*)<\infty</script>. It also implies that strong duality holds. </p>
<p><strong>3.2.1 Convergence</strong> </p>
<ul>
<li>
<p><em>Residual convergence.</em> <script type="math/tex">r^k \rightarrow0</script> as <script type="math/tex">k \rightarrow\infty</script>. </p>
</li>
<li>
<p><em>Objective convergence.</em>  <script type="math/tex">f(x^k )+g(z^k)\rightarrow p^*  \mbox{as}\  k\rightarrow\infty</script>. </p>
</li>
<li>
<p><em>Dual variable convergence.</em> <script type="math/tex">y^k\rightarrow y^* \mbox{as}\ k\rightarrow \infty </script>, where <script type="math/tex">y^*</script> is a dual optimal point. </p>
</li>
</ul>
<p>Note that <script type="math/tex">x^k</script> and <script type="math/tex">z^k</script> need not converge to optimal values. </p>
<p>â€‹</p>
<p><strong>3.2.2 Convergence in Practice</strong></p>
<p>The general case ADMM will be practically useful mostly in cases when modest accuracy is sufficient. </p>
<h5 id="optimality-conditions-and-stopping-criterion">Optimality Conditions and Stopping Criterion</h5>
<p>The necessary and sufficient optimality conditions for the ADMM problem (3.1) are primal feasibility,
<script type="math/tex; mode=display">
Ax^*+Bz^*-c=0 \tag{3.8}
</script>
and dual feasibility,
<script type="math/tex; mode=display">
\begin{align}
0\in \partial f(x^*)+A^Ty^* \tag{3.9}\\
0\in \partial g(z^*)+B^Ty^* \tag{3.10}
\end{align}
</script>
Here, <script type="math/tex">\partial</script> denotes the <em>subdifferential operator</em>.  </p>
<p>Since <script type="math/tex">z^{k+1}</script> minimizes <script type="math/tex">L_\rho (x^{k+1},z,y^k)</script> by definition, we have
<script type="math/tex; mode=display">
\begin{align}
0&\in\partial g(z^{k+1})+B^Ty^k+\rho B^T(Ax^{k+1}+Bz^{k+1}-c)\\
&=\partial g(z^{k+1})+B^Ty^k+\rho B^Tr^{k+1}\\
&=\partial g(z^{k+1})+B^Ty^{k+1}
\end{align}
</script>
This means that <script type="math/tex">z^{k+1}</script> and <script type="math/tex">y^{k+1}</script> always satisfy (3.10). Now we have to optimize (3.8) and (3.9). </p>
<p>Since <script type="math/tex">x^{k+1}</script> minimizes <script type="math/tex">L_\rho (x,z^{k},y^k)</script> by definition, we have
<script type="math/tex; mode=display">
\begin{align}
0&\in\partial f(x^{k+1})+A^Ty^k+\rho A^T(Ax^{k+1}+Bz^{k}-c)\\
&=\partial f(z^{k+1})+A^T(y^k+\rho r^{k+1}+\rho B(z^k-z^{k+1}))\\
&=\partial f(z^{k+1})+A^Ty^{k+1} +\rho A^TB(z^k-z^{k+1})
\end{align}
</script>
or equivalently,
<script type="math/tex; mode=display">
\rho A^TB(z^{k+1}-z^{k}) \in \partial f(x^{k+1})+A^Ty^{k+1}
</script>
We define <script type="math/tex">s^{k+1} = \rho A^TB(z^{k+1}-z^{k}) </script> as the <em>dual residual</em> at iteration <script type="math/tex">k+1</script>, and <script type="math/tex">r^{k+1}=Ax^{k+1}+Bz^{k+1}-c</script> as the <em>primal residual</em> at iteration <script type="math/tex">k+1</script>. These two resuduals converge to zero as ADMM proceeds. The (3.10) always holds for <script type="math/tex">(x^{k+1},z^{k+1},y{k+1})</script>. </p>
<p><strong>3.3.1 Stopping criteria</strong></p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="../Augmented Lagrangians and the Method of Multipliers/" class="btn btn-neutral" title="ADMM"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../Augmented Lagrangians and the Method of Multipliers/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      <script src="../search/require.js"></script>
      <script src="../search/search.js"></script>

</body>
</html>
